### 一、多线程及JVM



##### 1. synchronized原理
代码块，锁对象的话：monitorEnter、monitorExit
方法：ACC_SYNCHROINZED
##### 2.锁的优化升级
无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁，还有锁消除、锁膨胀
##### 3.锁的对象头包含的内容
对象包含的数据有对象头，实例数据，对齐填充
对象头里有markword、类元数据；
而MARKWORD中又存了对象的HashCode、分代年龄、锁标记位

##### 4、ReentrantLock的原理以及与synchronized的区别
AQS框架，持有一个volatile修饰的state变量，一个是API，一个jvm层面，支持非公平、公平锁，需要手动释放，可以设置超时时间
##### 5、AQS原理

##### 6、CAS原理以及缺点，ABA问题如何解决
cas优点：如一描述在并发量不是很高时cas机制会提高效率。
cas缺点：
1、cpu开销大，在高并发下，许多线程，更新一变量，多次更新不成功，循环反复，给cpu带来大量压力。
2、只是一个变量的原子性操作，不能保证代码块的原子性。
加版本号可以解决
##### 7. volatile原理
可见性，强制主内存的变量刷新到工作内存
禁止指令重排序，生成指令后会插入内存屏障，
读：前面LoadLoad、后面加LoadStore
写：前端StoreStore，后面加StoreLoad

##### 8. jmm内存模型
主内存 -> 工作内存模型

##### 9.CountDownLatch、CycleBarrier、Semaphore区别
计数器（主线程等其他线程完成后再执行），栅栏（所有线程统一执行到一个点，等待，然后再一起执行），信号量（控制线程数）
##### 10.什么是Happen-before以及as-if-seraial

##### 11.什么是逃逸分析

##### 12.ThrealLocal原理以及应用场景
ThreadLocal类用来提供线程内部的局部变量。这种变量在多线程环境下访问（通过get和set方法访问）时能保证 各个线程的变量相对独立于其他线程内的变量。ThreadLocal实例通常来说都是private static类型的，用于关联线程和线程上下文。
ThreadLocal方案的好处
数据传递 ： 保存每个线程绑定的数据，在需要的地方可以直接获取, 避免参数直接传递带来的代码耦合

线程隔离 ： 各线程之间的数据相互隔离却又具备并发性，避免同步方式带来的性能损失。
每一个Thread线程，单独维护一个ThreadLocalMap，这个对应Map的key为ThreadLocal实例本身，value为我们需要存储的值，是一个Object类型。

为什么使用弱引用？
因为使用弱引用不会影响ThreadLocal对象被释放后的垃圾回收，由于使用了弱引用，
被释放的对象只能存活到下一次gc，对象被回收后弱引用就变为null，这时候就可以进行判断这个位置的条目是否已经是旧条目，
从而进行清理。防止内存泄漏，

##### 13.线程池原理，以及在正式开发中如何使用（自定义线程池，带名字，方便排查，线程池的参数如何设置），如何避免内存泄漏的问题。线程池的拒绝策略。如何自己实现拒绝策略
为什么先放队列里而不是先创建线程直到最大线程数？
在创建新线程的时候，是要获取全局锁的，这个时候其它的就得阻塞，影响了整体效率。
|

fixed：corePoolSize = maximumPoolSize，LinkedBlockingQueuesingled： coolPoolSize = maximumPoolSize = 1，BlockingQueue
newCachedThreadPool： coolPoolSize = 0，maximumPoolSize=Integer.Max_value,KeepAliveTime = 60L,SynchronousQueue
newScheduledThreadPool coolPoolSize等于传入的值，maximumPoolSize=INTEGER.MAX_VALUE
##### 14. 强软弱虚四种引用的区别
软：空间足够不会回收，不够就会回收，软引用可用来实现内存敏感的高速缓存
弱：不够够不够都会回收，弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。
虚：虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之 关联的引用队列中。

##### 15.有哪些阻塞队列以及非阻塞队列
阻塞队列：ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、PriorityBlockingQueue、DelayQueue
非阻塞队列：ConcurrentLinkedQueue、LinkedTransferQueue
##### 16. 类加载的机制，双亲委派机制的好处，以及如何打破双亲委派机制。哪些中间件或者框架打破了双亲委派机制
BootStrapClassLoader、ExtClassLoader、ApplicationClassLoader。
1、加载，通过类名获取二进制字节流，将字节流代表的静态存储结构转化为方法去的运行时数据结构，在内存中生成对象，作为方法去这个类的各种数据的访问入口。
2.验证，确保被加载的类的安全性
3.准备，为类的静态变量分配内存，并将其赋默认值
4、解析，常量池中的符号引用替换为直接引用。 符号引用就是一组符号来描述目标，可以是任何字面量。属于编译原理方面的概念如：包括类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。如指向方法区某个类的一个指针
5、初始化：为类的静态变量赋值。
6.使用
7.卸载
参考文章：https://blog.csdn.net/zhaocuit/article/details/93038538
##### 17.JVM内存模型，哪些区域是线程共享的，哪些是线程私有的
堆共享，pc、本地方法栈，虚拟机栈是线程私有的，方法区共享（静态变量和常量在方法区）
##### 18. JVM如何判定对象是否需要被回收
引用计数法、可达性分析
##### 19.哪些对象可作为gcroot?
- 虚拟机栈中引用的对象
- 方法区中静态属性、常量引用的变量（static、final修饰的变量）
- 本地方法栈中JNDI引用的对象



##### 20.常见的垃圾回收算法，以及分代回收的流程
标志清除，内存碎片
复制 内存空间利用不足
标记整理 ，效率低
分代回收：
新生代：复制
老年代：标记-整理
新生代：老年代 = 1:2
##### 21.哪些常用的垃圾回收器，分别有什么区别
 > CMS和G1的区别
- 使用范围：CMS使用在老年代，可以配合新生代的serial和parNew收集器一起使用；G1的使用范围是老年代和新生代。不需要结合其他收集器使用。
- STW时间：CMS以最小的停顿时间为目标；G1可以预测垃圾回收的停顿时间（建立可预测的停顿时间模型）
- 垃圾碎片：CMS收集器使用标记-清除算法，容易产生内存碎片；G1使用标记-整理算法，还可以划分区域进行按区回收，降低了内存空间碎片。
- 垃圾回收过程：
CMS:1.初始标记；2.并发标记；3.重新标记；4：并发清除
G1： 1.初始标记；2：并发标记：3：最终标记：4、筛选回收

##### 22.常见的JVM参数配置
-Xms 初始堆的大小，默认为物理内存的1/64
-Xmx 最大堆大小，默认为物理内存的1/4
-Xmn 年轻代大小（1.4版本或之后的版本）。（整个堆=年轻代+老年代+持久代（1.8后移除了永久代，改为在直接内存上分配元空间））
-XX:NewSize (1.3/1.4版本)
-XX:MaxNewSize	年轻代最大值(for 1.3/1.4)
-XX:PermSize 设置持久代(perm gen)初始值
-Xss 每个线程的堆栈大小。如果栈不是很深， 应该是128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。（校长）
-XX:NewRatio 年轻代与老年代的比值
-XX:SurvivorRatio Eden区和Survivor区的比值
-XX:+UseParNewGC 设置年轻代为并行收集，可与CMS同事使用
-XX:+UseParallelOldGC 年老代垃圾收集方式为并行收集(Parallel Compacting)
-XX:+ScavengeBeforeFullGC Full GC前调用YGC
-XX:+PrintGC
-XX:+PrintGCDetails
 -XX:+HeapDumpOnOutOfMemoryError
##### 23. cpu过高如何排查
top -hp -> jstack -> 找出堆栈信息
##### 24.内存溢出如何排查，栈内存溢出如何排查，死锁如何排查，以及如何破坏死锁
-> jvm参数设置，或者手动jmap -dump:live,format=b,file=myjmapfile.txt 19570 命令，然后使用mat工具
##### 25. 频繁发生FullGC如何排查
拿到dump日志
旧生代空间不足。
Permanet Generation空间满了(1.8后取消了永久代，改为元空间，使用直接内存)
通过Minor GC后进入老年代的平均大小大于老年代的可用内存
由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代可用内存不足(老年代可用内存小于该对象)

##### 26.垃圾回收底层原理

##### 27.有哪些常用的JVM问题排查工具



##### 28.栈桢

##### 29. TLAB问题

##### 30. 什么时候进行FullGC，什么时候进行YGC，对象什么时候进入老年代，什么是分配担保机制？
Fullgc：Permanet Generation空间满了，老年代空间不足，通过Minor GC后进入老年代的平均大小大于老年代的可用内存，systen.gc
ygc:edn空间不足

##### 31 线程池在使用过程中遇到过什么问题？
线程池未命名、不允许通过Executors创建、线程池隔离
##### 32 对象的创建过程
##### forkjoin
##### 线程池为什么要先放到队列中去而不是先创建线程以满足最大线程数
1、降低资源消耗，提升线程的利用率，降低创建和销毁线程的消耗；
2、线程池创建线程需要获取mainLock全局锁，影响并发效率，所以使用阻塞队列把第一步创建核心线程与第三部创建最大线程隔离开来，起一个缓冲的作用。
3、引入阻塞队列，是为了在执行execute方法时，尽可能的避免获取全局锁

##### 如何设置线程数，线程数怎么取值比较好？
获取cpu核数：Runtime.getRuntime().availableProcessors()
1、cpu密集型：cpu核数+ 1。
2、IO密集型：cpu*2






























### 二、Java基础、容器

##### 1. HashMap原理

##### 2. put原理（1.7和1.8区别）

#### 为什么hashMap不是线程安全的
多个线程同时写的话数据会丢失。
1.7在并发场景下多个线程同时插入可能导致死循环。
##### 3.hashMap如何进行扩容
复制一个容量为2倍的数组，然后重新rehash
##### 4.长度为什么要是2的幂次方
可以减少碰撞几率，2的倍数 -1 得到值所有位都是1，和计算值相与后能保证结果单一，如果位上的0越多，碰撞概率越大。

比如容量是2的4次方 减1就是 1111.。。那么计算值1110过来和他相与， 结果是1110，另一个计算值1111和他相与结果仍是1111 各自结果不一样 不会碰撞 如果容量不是2的4次方 比如15 减1就是1110. 那么计算值1110过来和他相与， 结果是1110，另一个计算值1111和他相与结果是1110 跟前一个一样 发生碰撞了
##### 5. ConcurrentHashmap原理

##### 6.ArrayList原理以及扩容机制
创建1.5倍容量的数组，调用Arrays.copyof方法复制数据
##### 7.函数式接口，lamada表达式
##### 有哪些常见的Queue，阻塞队列，非阻塞队列
##### 8 如何解决hash冲突
1、链表法，每一个桶都会对应一条链条，所有哈希值相同的元素放到相同槽位的对应的链表
2、开放寻址法：如果出现冲突，就重新探测一个空闲位置，再将元素插入。
探测方法：1、线性探测法，；2、二次探测法；3、双重散列法









### 三、计算机网络以及操作系统

##### 1.什么是零拷贝zero-copy
主要就是利用各种零拷贝技术，避免让CPU做大量的数据拷贝任务，减少不必要的拷贝，或者让别的组件来做这一类简单的数据传输任务，让CPU解脱出来专注于别的任务。这样就可以让系统资源的利用更加有效。
减少数据在内核空间和用户空间来回拷贝
https://mp.weixin.qq.com/s/FgBCop2zFfcX5ZszE0NoCQ
##### 2.三次握手四次挥手，为什么是三次握手而不是两次或者四次

##### 3.linux常用命令
查看tcp连接数 netstat -nat|grep -i "80"|wc -l
查看linux后十行日志
> tail -n 50 info.log
查詢日誌某關鍵字前後十行
> grep -C 10 'keyword' info.log

查询日志某关键字上面十行
> grep -B 10 'keyword' info.log

查询日志某关键字下面十行
> grep -A 10 'keyword' info.log
##### 4. TCP、UDP、Http区别。TCP重传、滑动窗口、流量控制，拥塞控制

TCP格式？
答：序列号，确认应答号，控制标志位

UDP 和 TCP 有什么区别呢？分别的应用场景是？
UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。
- TCP 是面向连接的传输层协议，传输数据前先要建立连接。UDP 是不需要连接，即刻传输数据。
- TCP 是一对一的两点服务，即一条连接只有两个端点。UDP 支持一对一、一对多、多对多的交互通信
- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。UDP 是尽最大努力交付，不保证可靠交付数据。
- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

应用场景区别？
- 由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：FTP 文件传输、HTTP / HTTPS
- 由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：包总量较少的通信，如 DNS 、SNMP 等、视频、音频等多媒体通信。广播通信

tcp如何保证可靠性？
答：TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。
TCP的重传机制？
答：TCP 实现可靠传输的方式之一，是通过序列号与确认应答。（重传机制）
接下来说说常见的重传机制：超时重传、快速重传、SACK、D-SACK
超时重传，党客户端发送报文给服务器，当在一定时间内没有收到ACK报文时，就会进行重发
TCP 还有另外一种快速重传（Fast Retransmit）机制，它不以时间为驱动，而是以数据驱动重传。

TCP滑动窗口？
答：每发送一个数据，就等服务器回ack的方式效率过低，所以引入了滑动窗口机制。TCP 引入了窗口这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。那么有了窗口，就可以指定窗口大小，窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。
通常窗口的大小是由接收方的决定的。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据

TCP流量控制？
TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制

TCP拥塞控制？
答：在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….
拥塞窗口 cwnd是发送方维护的一个 的状态变量，它会根据网络的拥塞程度动态变化的。

为什么是三次握手？不是两次、四次？
- 三次握手才可以阻止历史重复连接的初始化（主要原因）
- 三次握手才可以同步双方的初始序列号
- 三次握手才可以避免资源浪费

为什么是四次挥手？
关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。
服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。

##### epoll，select
##### HTTPS协议
前面说到，HTTPS其实就是将HTTP的数据包再通过SSL/TLS加密后传输，那么SSL/TLS又是什么呢？

SSL（Secure Sockets Layer）安全套接层和TLS（Transport Layer Security）传输层安全协议其实是一套东西。
工作流程：
1、用户在浏览器发起HTTPS请求（如 https://www.mogu.com/），默认使用服务端的443端口进行连接；
2、HTTPS需要使用一套CA数字证书，证书内会附带一个公钥Pub，而与之对应的私钥Private保留在服务端不公开；
3、服务端收到请求，返回配置好的包含公钥Pub的证书给客户端；
4、客户端收到证书，校验合法性，主要包括是否在有效期内、证书的域名与请求的域名是否匹配，上一级证书是否有效（递归判断，直到判断到系统内置或浏览器配置好的根证书），如果不通过，则显示HTTPS警告信息，如果通过则继续；
5、客户端生成一个用于对称加密的随机Key，并用证书内的公钥Pub进行加密，发送给服务端；
6、服务端收到随机Key的密文，使用与公钥Pub配对的私钥Private进行解密，得到客户端真正想发送的随机Key；
7、服务端使用客户端发送过来的随机Key对要传输的HTTP数据进行对称加密，将密文返回客户端；
8、客户端使用随机Key对称解密密文，得到HTTP数据明文；
9、后续HTTPS请求使用之前交换好的随机Key进行对称加解密。

为了兼顾性能和安全性，使用了非对称加密+对称加密的方案。

为了保证公钥传输中不被篡改，又使用了非对称加密的数字签名功能，借助CA机构和系统根证书的机制保证了HTTPS证书的公信力。









### 四、Netty、NIO







### 五、Redis

##### 1.五种数据结构，底层分别是什么数据结构实现的，以及应用场景，

##### 2. 缓存雪崩、缓存穿透、缓存击穿区别以及解决方案
缓存雪崩：
- 过期时间加随机值
- 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中
- 设置热点数据永远不过期。
缓存穿透：
- 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
- 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
- 布隆过滤器

缓存击穿：
- 设置热点数据永远不过期。
- 加互斥锁，互斥锁参考代码如下：
##### 3. 描述一下跳表

##### 4、如何保证缓存一致性，以及缓存与数据库先更新哪个
    缓存场景是非强一致性场景，根据cap理论，不可能达到强一致性，只满足AP。
    所以，我们得委曲求全，可以去做到BASE理论中说的最终一致性。
    最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性
 ######方案1：先删缓存，再更新数据库。可能存在数据不一致的问题
>  1.假设有A,B两个线程，A线程进行写操作，B线程进行读操作。
>  2.A线程先执行，将缓存删掉，写操作还未完成。B线程开始读操作，此时发现缓存中没有数据。于是读取数据库，此时B线程读到的是旧值。
>  3.B线程读到旧值后，将旧值写入缓存中。
>  4.A线程写操作完成。此时发生数据不一致的情况。
>  5.如何B线程对数据设置永不过期的话，会造成很严重的问题，缓存中永远都是错误数据。
>
###### 方案2：先更新数据库，在删缓存。在并发场景也会出现问题
可能存在的问题：A线程做查询操作，B线程做更新操作
1.缓存刚好失效。
2.请求A请求数据库，得到一个旧值。
3.线程B更新数据库，
4.然后删除缓存。
5.线程A就旧值写入缓存。此时缓存就是旧值，从而与数据库值不一致。
但要发生上述情况，需要步骤3中写数据库的操作比步骤2中的读操作更短，才会发生数据不一致的情况。但一般而言写操作比读操作是耗时要更长的，所以这种方案发生不一致问题得概率相比方案1要小很多。

**为了解决方案1、方案2导致数据不一致的问题，可以考虑达到数据最终一致性来解决**
##### 缓存延时双删
方案1延时双删步骤：
1.先淘汰缓存；2。再写缓存。3.休眠一秒，再删除一次缓存。
注意：针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。
采用上述方案吞吐量降低怎么办，可以考虑将第二次删缓存做成异步的
**如果删除缓存失败了怎么处理？**
可以使用重试机制

方案2：第二种方案：异步更新缓存(基于订阅binlog的同步机制)
    
    技术整体思路：
    
    MySQL binlog增量订阅消费+消息队列+增量数据更新到redis
    
    读Redis：热数据基本都在Redis
    写MySQL:增删改都是操作MySQL
    更新Redis数据：MySQ的数据操作binlog，来更新到Redis
    Redis更新
    
    1）数据操作主要分为两大块：
    
    一个是全量(将全部数据一次写入到redis)
    一个是增量（实时更新）
    这里说的是增量,指的是mysql的update、insert、delate变更数据。
    
    2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。
    
    这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。
    
    其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。
    
    这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果

参考文章：
https://blog.csdn.net/qq_42914528/article/details/113153537?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-1&spm=1001.2101.3001.4242



 

##### 5. redis持久化
1、RDB
2、AOF
##### 6.如何保证redis的高可用，redis的集群部署方案，以及描述一下redis cluster方案，以及如何保证集群中的节点数据一致
1、redis一主多从，加哨兵机制。可以实现故障转移。
2、使用redis cluster集群方案
##### 7. redis的IO多路复用机制，以及为什么效率这么高
IO多路复用程序会同时监听多个socket，当被监听的socket准备好执行accept、read、write、close等操作时，
与这些操作相对应的文件事件就会产生。IO多路复用程序会把所有产生事件的socket压入一个队列中，
然后有序地每次仅一个socket的方式传送给文件事件分派器，
文件事件分派器接收到socket之后会根据socket产生的事件类型调用对应的事件处理器进行处理。
##### 8.如何使用redis实现分布式锁，如何生成分布式id
利用 redis 单线程,不能存储相同key,可以设置存储数据失效的特性实现分布式锁,重点方法时setnx(),存储,存储成功返回1,失败返回0,
需要设置超时时间，防止服务宕机后无法释放锁。
要想实现可重入锁，需要通过lua脚本实现
脚本如下：
```
if redis.call("get", KEYS[1]) == ARGV[1] then 
     return redis.call("del", KEYS[1]) 
 else 
     return 0 
 end 
```
##### 9.在使用redis有没有遇到什么问题，在项目中使用redis做了什么

##### 15、分布式锁，redisson是如何解决死锁问题
https://blog.csdn.net/luokn1995/article/details/108371863

分布式锁的各种坑，以及解决方案。参考下列
> http://www.360doc.com/content/20/0428/07/58006001_908837125.shtml
Redlock为了解决单机的问题，需要多个（大于2）redis的master节点，多个master节点互相独立，没有数据同步。

##### 10.redis过期策略以及淘汰机制
redis的过期策略是：定期删除+惰性删除.
redis 内存淘汰机制（内存淘汰策略）有以下几个：
• noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。
• allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。
• allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。
• volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。
• volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。
• volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。

allkeys-lru：如果我们的应用对缓存的访问符合幂律分布，也就是存在相对热点数据，或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择allkeys-lru策略。

allkeys-random：如果我们的应用对于缓存key的访问概率相等，则可以使用这个策略。

volatile-ttl：这种策略使得我们可以向Redis提示哪些key更适合被eviction。
##### 11. redis为什么是原子性的，如何保证的
因为Redis是单线程的。Redis本身提供的所有API都是原子操作，Redis中的事务其实是要保证批量操作的原子性。

##### bigkey会造成什么后果?
如果下面两种情况，我就会认为它是bigkey。

字符串类型：它的big体现在单个value值很大，一般认为超过10KB就是bigkey。
非字符串类型：哈希、列表、集合、有序集合，它们的big体现在元素个数太多。
危害：
1.内存空间不均匀。这样会不利于集群对内存的统一管理，存在丢失数据的隐患。
2.超时阻塞。由于Redis单线程的特性，操作bigkey的通常比较耗时，也就意味着阻塞Redis可能性越大，这样会造成客户端阻塞或者引起故障切换，它们通常出现在慢查询中。
3.网络拥塞。bigkey也就意味着每次获取要产生的网络流量较大
4..过期删除。就会存在阻塞Redis的可能性，而且这个过期删除不会从主节点的慢查询发现
5.迁移困难。当需要对bigkey进行迁移（例如Redis cluster的迁移slot），实际上是通过migrate命令来完成的，migrate实际上是通过dump + restore + del三个命令组合成原子命令完成，如果是bigkey，可能会使迁移失败，而且较慢的migrate会阻塞Redis。

bigkey怎么产生的？
 一般来说，bigkey的产生都是由于程序设计不当，或者对于数据规模预料不清楚造成的，来看几个：
 
 (1) 社交类：粉丝列表，如果某些明星或者大v不精心设计下，必是bigkey。
 
 (2) 统计类：例如按天存储某项功能或者网站的用户集合，除非没几个人用，否则必是bigkey。
 
 (3) 缓存类：将数据从数据库load出来序列化放到Redis里，这个方式非常常用，但有两个地方需要注意:
 
 第一，是不是有必要把所有字段都缓存
 第二，有没有相关关联的数据
 例如遇到过一个例子，该同学将某明星一个专辑下所有视频信息都缓存一个巨大的json中，造成这个json达到6MB，后来这个明星发了一个官宣
 bigkey怎么发现？
 redis-cli提供了--bigkeys来查找bigkey
 
 如何优化bigkey？
 1、拆分
 2、
##### 多主多从的架构下redis如何互相同步状态
#### 一致性hash为了解决什么问题
> 解决redis扩容时hash到原先节点上去，造成缓存雪崩的问题
>https://blog.csdn.net/cy973071263/article/details/104497894

一致性hash原理
一致性Hash算法也是使用取模的方法，不过，上述的取模方法是对服务器的数量进行取模，而一致性的Hash算法是对2的32方取模。即，一致性Hash算法将整个Hash空间组织成一个虚拟的圆环，Hash函数的值空间为0 ~ 2^32 - 1(一个32位无符号整型)
将数据Key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针查找，遇到的服务器就是其应该定位到的服务器。
一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，有很好的容错性和可扩展性。

一致性hash算法如何解决数据倾斜问题？
为了解决数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务器节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。
一致性哈希的哈希槽数为什么是2^32

一致性哈希一定程度上也解决了哈希冲突，只要哈希槽的范围足够大就能尽可能的减少哈希冲突，因为通常的hashCode都是将数据映射到0 ~ 2^32 数值空间内，所以设置一个2^32个节点的哈希环会尽可能的减少哈希冲突。
##### redis bigkey会造成什么问题
##### redis哨兵机制保证高可用。
> 哨兵机制是一主多从，同时需要保证哨兵也是集群部署，避免单点故障
###### 哨兵作用
- 集群监控，负责监控master和slave的状态
- 消息通知，如果redis节点发生故障，则哨兵会发消息通知管理员
- 故障转移：如果master节点宕机，则会自动从slaver选取新的节点作为master
- 配置中心，如果发生了故障转移，则会通知client端新的master地址
###### 哨兵的高可用
- 多个哨兵节点共同监控集群状态
- 哨兵之间会互相通信，交换主从节点的状态
- 每隔1s每个哨兵会向整个集群（master+slaver+哨兵）发送一次心跳检测
一个哨兵判定主节点down叫做主观下线，超过一半的哨兵都认为主节点down，，然后哨兵相互交换判定结果，成为客观下线
##### redis复制
全量同步：
> 复制原理：
>   1.slaver启动时，slaver向master发送sync指令
>   2.master收到sync指令后，master节点会fork出一个子进程，子进程和父进程共享数据段，生成rdb文件快照。
>   3.当客户端有写指令时，同时master会缓存所有的写指令到缓冲区，
>   4.master发送rdb文件和写指令给slaver
>   5.slaver初始化rdb文件，并执行写指令，实现数据的同步
>   注意：在Redis2.8之后，主从断开重连后会根据断开之前最新的命令偏移量进行增量复制

增量：
Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 
增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令
##### redis主从、哨兵、集群的区别
主从：主要是为了数据备份，负载均衡，可以读写分离，一主多从模式
哨兵：为了高可用，实现故障转移
cluster：为了解决单机redis容量有限的问题，将数据按照一定的规则分发到不同的机器上，内存qps不受限与单机，可以分布式扩展

##### redis cluster
要求至少3个master，同时每个master至少需要一个slave结点
1.把16384槽按照节点数量进行平均分配，由节点进行管理
2.对每个key按照CRC16规则进行hash运算
3.把hash结果对16383进行取余
4.把余数发送给Redis节点
5.节点接收到数据，验证是否在自己管理的槽编号的范围
    如果在自己管理的槽编号范围内，则把数据保存到数据槽中，然后返回执行结果
    如果在自己管理的槽编号范围外，则会把数据发送给正确的节点，由正确的节点来把数据保存在对应的槽中
https://www.cnblogs.com/williamjie/p/11132211.html

##### reids cluster集群下如何同步各个结点的状态，以及新加入的结点如何加入集群
meet消息：用于通知新节点加入。消息发送者通知接收者加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换。
ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。ping消息发送封装了自身节点和部分其他节点的状态数据。
pong消息：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内部封装了自身状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。
fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。
举例当新增一个节点，也就是Meet消息过程

节点A会为节点B创建一个clusterNode结构，并将该结构添加到自己的clusterState.nodes字典里面。
节点A根据CLUSTER MEET命令给定的IP地址和端口号，向节点B发送一条MEET消息。
节点B接收到节点A发送的MEET消息，节点B会为节点A创建一个clusterNode结构，并将该结构添加到自己的clusterState.nodes字典里面。
节点B向节点A返回一条PONG消息。
节点A将受到节点B返回的PONG消息，通过这条PONG消息节点A可以知道节点B已经成功的接收了自己发送的MEET消息。
之后，节点A将向节点B返回一条PING消息。
节点B将接收到的节点A返回的PING消息，通过这条PING消息节点B可以知道节点A已经成功的接收到了自己返回的PONG消息，握手完成。
之后，节点A会将节点B的信息通过Gossip协议传播给集群中的其他节点，让其他节点也与节点B进行握手，最终，经过一段时间后，节点B会被集群中的所有节点认识。
##### 布隆过滤器原理
.应用场景，网页黑名单，垃圾邮件过滤，电话黑名单，url去重，内容推荐等
存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素
删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断
##### 什么是分布式共识算法
> 在一个分布式系统中，如何保证集群中所有节点中的数据完全相同并且能够对某个提案（Proposal）达成一致是分布式系统正常工作的核心问题，而共识算法就是用来保证分布式系统一致性的方法。

Paxos算法：
Raft算法：
Zab





### 六、RPC框架
##### 1. RPC和http的区别，为什么要用rpc框架，为什么选用dubbo
##### 2.dubbo的总体架构，以及大体工作流程
##### 3.dubbo如何设置直连，一般用于本地测试
1、 文件映射（接口较多情况下）
2、consumer的<dubbo:reference>中配置url属性指向提供者地址
3、在consumer端的JVM启动参数中加入-D参数映射服务地址，如：(key为服务名，value为服务提供者url，此配置优先级最高)
  -Dcom.xxxxx.wms.sservice.WWhCommandService=dubbo://localhost:20890
  
##### 4.如何升级dubbo接口
dubbo提供接口服务多版本管理
##### 5.描述一下dubbo的spi机制
Dubbo 就依靠 SPI 机制实现了插件化功能，几乎将所有的功能组件做成基于 SPI 实现，并且默认提供了很多可以直接使用的扩展点，实现了面向功能进行拆分的对扩展开放的架构。
Java SPI源码分析
1、获取当前线程的ClassLoader。没有的话就用默认的SystemClassLoader
2、然后去定义好的目录下找文件，然后解析加载指定的类
3、创建类的实例
Java SPI缺点：
Java SPI 在查找扩展实现类的时候遍历 SPI 的配置文件并且将实现类全部实例化，假设一个实现类初始化过程比较消耗资源且耗时，但是你的代码里面又用不上它，这就产生了资源的浪费。
所以说 Java SPI 无法按需加载实现类。
DUBBO spi机制
Dubbo 就自己实现了一个 SPI，让我们想一下按需加载的话首先你得给个名字，通过名字去文件里面找到对应的实现类全限定名然后加载实例化即可。

Dubbo 就是这样设计的，配置文件里面存放的是键值对，我截一个 Cluster 的配置.
并且 Dubbo SPI 除了可以按需加载实现类之外，增加了 IOC 和 AOP 的特性，还有个自适应扩展机制。

我们先来看一下 Dubbo 对配置文件目录的约定，不同于 Java SPI ，Dubbo 分为了三类目录。
META-INF/services/ 目录：该目录下的 SPI 配置文件是为了用来兼容 Java SPI 。
META-INF/dubbo/ 目录：该目录存放用户自定义的 SPI 配置文件。
META-INF/dubbo/internal/ 目录：该目录存放 Dubbo 内部使用的 SPI 配置文件。
Adaptive 注解 - 自适应扩展
我们先来看一个场景，首先我们根据配置来进行 SPI 扩展的加载，但是我不想在启动的时候让扩展被加载，我想根据请求时候的参数来动态选择对应的扩展。

怎么做呢？

Dubbo 通过一个代理机制实现了自适应扩展，简单的说就是为你想扩展的接口生成一个代理类，可以通过JDK 或者 javassist 编译你生成的代理类代码，然后通过反射创建实例。

这个实例里面的实现会根据本来方法的请求参数得知需要的扩展类，然后通过 ExtensionLoader.getExtensionLoader(type.class).getExtension(从参数得来的name)，来获取真正的实例来调用。



##### 6.描述一下dubbo的服务暴露过程
> https://mp.weixin.qq.com/s/ISiN06QynyE2pPtX3cGQ9w
##### 7.描述一下dubbo服务引用的过程
> https://mp.weixin.qq.com/s/9oDy1OPcfDaEhKD4eNUdOA
##### 8.描述一下服务调用的过程
> https://mp.weixin.qq.com/s/oNR9v_ID2oAlEvDI93hRcw
##### 9. 为什么要封装成 invoker?
它也就代表一个可执行体，提供方和服务方都可用，至于为什么要封装成 invoker 其实就是想屏蔽调用的细节，统一暴露出一个可执行体，这样调用者简单的使用它，向它发起 invoke 调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。
##### 10.为什么有本地协议？
存在一些服务既是服务提供方有事消费端，防止走网络通信
##### 11.DUBBO支持的协议和序列化协议有哪几种？
dubbo：单一长连接，传输数据量小，并发量高，使用hessian序列化协议
rmi协议：走java二进制序列化，多个短连接，适合消费者和提供者数量差不多，适用于文件的传输，一般较少用
hessian协议：多个短连接，适用于提供者数量比消费者数量还多，适用于文件的传输，一般较少用
http：走json序列化
webservice：走SOAP文本序列化
序列化协议：
dubbo 支持 hession、Java 二进制序列化、json、SOAP 文本序列化多种序列化协议。但是 hessian 是其默认的序列化协议。
##### 12.dubbo负载均衡策略
1、RandomLoadBalance；2、RoundRobinLoadBlance；3、LeastActiveLoadBlance；4、ConsistentHashLoadBalance

##### 13.dubbo三种调用方式
##### 14. zk有哪几种角色？
###### 一致性hash为了解决什么问题？
为了解决当有节点增加或删除时hash到其他位置上去了，造成大量的存储位置失效。
##### 16. dubbo容错策略
1、Failover Cluster。失败自动切换，当出现失败，重试其它服务器 。通常用于读操作，但重试会带来更长延迟。可通过 retries="2" 来设置重试次数(不含第一次)。
2、Failfast Cluster。快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。
3、Failsafe Cluster、失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作
4、Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。
5、Forking Cluster。并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks="2" 来设置最大并行数。
6、Broadcast Cluster。广播调用所有提供者，逐个调用，任意一台报错则报错 。通常用于通知所有提供者更新缓存或日志等本地资源信息
默认为Failover

##### 如何自己设计一个类似dubbo的rpc框架？
1、注册中心、高可用（nacos、consule、eruke、zk）
2、接着你就该发起一次请求了，咋发起？蒙圈了是吧。当然是基于动态代理了，你面向接口获取到一个动态代理，这个动态代理就是接口在本地的一个代理，然后这个代理会找到服务对应的机器地址。
3、然后找哪个机器发送请求？那肯定得有个负载均衡算法了，比如最简单的可以随机轮询是不是
4、网络通信：接着找到一台机器，就可以跟他发送请求了，第一个问题咋发送？你可以说用netty了，nio方式
5、序列化：hessian序列化协议了，或者是别的，对吧。然后请求过去了。
6、指定协议，使用http、dubbo协议。

##### 当⼀个服务接⼝有多种实现时怎么做？
当⼀个接⼝有多种实现时，可以⽤ group 属性来分组，服务提供⽅和消费⽅都指定同⼀个 group 即可。

##### spi做了什么操作
DubboAccessLogFilter，重写AccessLogFilter
DubboExceptionFilter 处理dubbo异常
//这个不是SPI机制，是spring.factory机制，可以自动配置starter
EnableAutoConfiguration = com.tenwit.common.autoconfigure.TenwitFileAutoConfiguration
配合条件注解注入不同的文件上传类：
BaseFileService、ExclusiveBaseFileService

Java SPI机制应用
ShardingDataAesEncryptor
LeafSegmentShardingKeyGenerator
LeafSnowflakeShardingKeyGenerator
ComplexSqlParsingHook
DbShardingKeyContextRoutingHook











### 七、Spring以及SpringCloud
##### 1. 描述一下IOc和aop，为什么要使用ioc，aop原理
ioc通过spring容器来负责对bean的加载；
aop通过动态代理来实现
##### 2. 描述一下循环依赖以及spring是如何解决循环依赖的
> 使用三级缓存，https://www.jianshu.com/p/8bb67ca11831
##### 3.描述一下bean的生命周期
> https://yemengying.com/2016/07/14/spring-bean-life-cycle/
##### 4.Spring的容器启动流程
1、资源定位：找到配置文件   
2、BeanDefinition载入和解析   
3、BeanDefinition注册   
4、bean的实例化和依赖注入
1、BeanDefinition载入、解析、注册
1、找到配置文件Resource。   
2、将配置文件解析成BeanDefinition   
3、将BeanDefinition向Map中注册   Map<name,beandefinition>
##### 5.Spring事务的隔离级别以及传播行为
隔离级别一共五种，加上default
Propagation.REQUIRED：如果当前存在事务，则加入该事务，如果当前不存在事务，则创建一个新的事务。
Propagation.SUPPORTS：如果当前存在事务，则加入该事务；如果当前不存在事务，则以非事务的方式继续运行。
Propagation.MANDATORY：如果当前存在事务，则加入该事务；如果当前不存在事务，则抛出异常。
Propagation.REQUIRES_NEW：重新创建一个新的事务，如果当前存在事务，延缓当前的事务。
Propagation.NOT_SUPPORTED：以非事务的方式运行，如果当前存在事务，暂停当前的事务。
Propagation.NEVER:以非事务的方式运行，如果当前存在事务，则抛出异常。
Propagation.NESTED：如果没有，就新建一个事务；如果有，就在当前事务中嵌套其他事务。

##### 6.Bean的socpe
> prototype,singleton,request、session、global session
##### 7.Springboot自动装配原理，以及如何自定义一个starter
> @springBootApplicaiton -> @EnableAutoConfighurtion -> Meta-info/SPRING.FACTORY文件下
##### 8.条件注解
##### 9.springcloud常用组件
##### 10.nacos健康检查，原理，常见的注册中心有哪几个，区别是什么，为什么选用nacos
##### 11.熔断、限流、降级、监控系统、网关、权限、日志，日志是如何进行采集上报的。有哪几种限流算法
##### gateway路由配置，以及和zuul的区别
##### 为什么使用bff层，如何分层，讲一下领域模型
##### 讲一下项目的架构图
##### ribon负载均衡有哪几种策略
> RoundRobinRule轮询（默认）、RandomRule随机、RetryRule轮询重试（重试采用的默认也是轮询）、WeightedResponseTimeRule响应速度决定权重：BestAvailableRule最优可用、AvailabilityFilteringRule
 ZoneAvoidanceRule
##### 柔性事务（最大努力送达型事务、TCC 事务）
CP：牺牲可用性。复制同步的协议一般使用严格的法定数协议 (Paxos、Raft、ZAB)或者2PC协议。CP类型的系统有MongoDB、HBase、 Zookeeper、Redis等。
AP：牺牲一致性。复制同步的协议一般使用非严格的法定数协议。AP类型的系统有 Couch DB、Cassandra、Amazon Dynamo等

https://blog.csdn.net/wsdc0521/article/details/108223310
##### 讲一下你了解的分库分表中间件的底层实现原理?
##### 熔断机制
> 
      










### 八 数据库Mysql
##### 1.innodb和myisaim区别
> 事务、行锁，外键、聚集索引，非聚集索引
##### 2.为什么使用b+树索引，索引结构，与b树的区别是
b+树只有叶子节点存数据，b+树查询效率比较稳定。b+树每页能存更多的索引，b树非叶子节点也会存储数据。
##### 3.事务的隔离级别，不同的隔离级别可能存在的问题，以及如何解决
读未提交 不会使用到mvcc机制
读已提交 会使用到mvcc机制，select时每个事物读的都是最新的Read view
可重复读 会使用mvcc机制，select时对每个事物都会开启一个Readview，每个事物读的都是自己的那个视图
串行化

##### 持久性的原理，redo日志
##### mvcc多版本控制，
> 只在读以提交和可重复读生效，读已提交：每一次select时都会生成一个视图；可重复读：第一次select时生成一个view，后续select都用这个view。
mvcc会在每一行上都生成两个隐藏列trx_id，roll_pointer；

参考文章：https://blog.csdn.net/SnailMann/article/details/94724197
##### 出现慢sql如何排查
##### 索引优化
##### explain各个字段的含义
##### 如何保证mysql的高可用，
> 主备、读写分离
>
##### 分库分表实现方案
垂直、水平
##### 数据库锁有哪几种
乐观锁、悲观锁、
页锁，表锁，行锁、间隙锁、next key lock = 间隙锁 + 行锁
##### 如何设计动态扩容的分库分表方案
> 停机扩容（不推荐）倍数扩容
>
##### 采用分库分表后历史数据如何迁移
> 编写程序同步历史数据，再利用mq进行双写操作
##### 用过哪些分库分表中间件,有啥优点和缺点,
##### 分片策略
- 标准分片策略（StandardShardingStrategy）它只支持对单个分片健（字段）为依据的分库分表，并提供了两种分片算法 PreciseShardingAlgorithm（精准分片）和 RangeShardingAlgorithm（范围分片）。
- 复合分片策略、SQL 语句中有>，>=, <=，<，=，IN 和 BETWEEN AND 等操作符，不同的是复合分片策略支持对多个分片健操作，自定义复合分片策略要实现 ComplexKeysShardingAlgorithm 接口，重新 doSharding()方法。

- 行表达式分片策略（InlineShardingStrategy）提供对 SQL语句中的 = 和 IN 的分片操作支持，它只支持单分片健。行表达式分片策略适用于做简单的分片算法，无需自定义分片算法，省去了繁琐的代码开发，是几种分片策略中最为简单的
- Hint分片策略 
> Hint分片策略（HintShardingStrategy）相比于上面几种分片策略稍有不同，这种分片策略无需配置分片健，分片健值也不再从 SQL中解析，而是由外部指定分片信息，让 SQL在指定的分库、分表中执行。ShardingSphere 通过 Hint API实现指定操作，实际上就是把分片规则tablerule 、databaserule由集中配置变成了个性化配置。
           举个例子，如果我们希望订单表t_order用 user_id 做分片健进行分库分表，但是 t_order 表中却没有 user_id 这个字段，这时可以通过 Hint API 在外部手动指定分片健或分片库。
           

##### 聚簇索引和唯一索引区别
##### redolog undolog binlog区别
redo log是InnoDB存储引擎层的日志，又称重做日志文件，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。在实例和介质失败（media failure）时，redo log文件就能派上用场，如数据库掉电，InnoDB存储引擎会使用redo log恢复到掉电前的时刻，以此来保证数据的完整性。

在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到redo log日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将redo log中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术，他的关键点是先写日志，再写磁盘。

有了redo log日志，那么在数据库进行异常重启的时候，可以根据redo log日志进行恢复，也就达到了crash-safe。

redo log日志的大小是固定的，即记录满了以后就从头循环写。













### 九、Docker以及K8S
##### docker常用命令
docker images，docker pull，docker start docker ps
docker exec -it，docker stop docker remove
##### 如何编写docker compose文件
##### K8S中pod的概念




### 十、消息队列以及Kakfa
##### rabbitmq各个名词
##### 交换机类型，fanout（发到所有队列）、direct（路由键完全屁匹配）、topic（正则匹配）、header
##### 如何实现延时队列
ttl+死信队列
##### 如何使用mq解决分布式事物，最大努力通知
##### 队列转发，通过插件可以配置队列与队列间的转发以及交换机与交换机之间的转发
##### rabbit如何保证高可用以及集群部署方案
##### kafka的架构
##### kafka为什么这么快
顺序读写，sendFile使用零拷贝。批量读写、分区分段+索引
##### 如何保证消息不丢失，重复消费的问题，以及如何保证mq的消费顺序
> 不丢失，
生产者端丢失：开启confirm模式
MQ丢失：开启MQ持久化模式，第一种：消息持久化
               RabbitMQ 的消息默认存放在内存上面，如果不特别声明设置，消息不会持久化保存到硬盘上面的，如果节点重启或者意外crash掉，消息就会丢失。
               
               所以就要对消息进行持久化处理。如何持久化，下面具体说明下：
               
               要想做到消息持久化，必须满足以下三个条件，缺一不可。
               
               1） Exchange 设置持久化
               
               2）Queue 设置持久化
               
               3）Message持久化发送：发送消息设置发送模式deliveryMode=2，代表持久化消息
1.消息持久化

2.设置集群镜像模式

3.消息补偿机制
消费端丢失：关闭自动ack，需要注意保证幂等性
开启ack机制，参考https://www.cnblogs.com/cnndevelop/p/12091348.html

不重复消费：
https://www.cnblogs.com/zhixie/p/13444213.html

消息有序性：

##### kafka如何抱枕高可用
##### kafka master节点挂了之后怎么办
##### kafka如何设置分区与消费者的数量关系
##### kafka主从节点数据如何同步，同步原理
##### kafak丢失数据
生产者丢失数据
0---表示不进行消息接收是否成功的确认；
1---表示当Leader接收成功时确认；
-1---表示Leader和Follower都接收成功时确认；

##### 为什么Kafka不支持读写分离？
在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。

Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:

(1)数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。

(2)延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。

##### 17.Kafka中是怎么体现消息顺序性的？
kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。
整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.
##### kafka leader选举机制
https://blog.csdn.net/yanshu2012/article/details/54894629



### 十一、项目的架构以及项目中遇到的难题
##### sharding复杂sql路由失败
##### threalLocal内存泄漏
##### 财智系统重构业务划分
##### 重构任务系统，使用设计模式优化代码，扩展性强
##### 微服务开发后本地测试较为困难，出了一套本地微服务测试方案
##### 服务平滑切换




### 十二、算法以及数据结构
##### 二分法排序
##### 链表
##### 数组操作，字符串操作
##### 二叉树的遍历，层序、锯齿、前序，中序，后序遍历
##### 拉钩教育的数据结构算法跟着写一遍




### 十三、设计模式
##### 单例模式的几种写法
##### 常用的几种设计模式以及spring中使用了哪些设计模式
##### 在项目中用了什么设计模式

##### 如何判断一个数是否在40亿个整数中
bitmap

##### 如何在10亿个数中找出前1000大的数
采用分治的思想，分成若干的文件，在每个文件中找出前1000，然后再结果中再进行排序。
可以维护一个最大堆












