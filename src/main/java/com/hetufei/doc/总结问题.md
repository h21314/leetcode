### 一、多线程及JVM



##### 1. synchronized原理
代码块，锁对象的话：monitorEnter、monitorExit
方法：ACC_SYNCHROINZED
##### 2.锁的优化升级
无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁，还有锁消除、锁膨胀
##### 3.锁的对象头包含的内容
对象包含的数据有对象头，实例数据，对齐填充
对象头里有markword、类元数据；
而MARKWORD中又存了对象的HashCode、分代年龄、锁标记位

##### 4、ReentrantLock的原理以及与synchronized的区别
AQS框架，持有一个volatile修饰的state变量，一个是API，一个jvm层面，支持非公平、公平锁，需要手动释放，可以设置超时时间
##### 5、AQS原理

##### 6、CAS原理以及缺点，ABA问题如何解决
cas优点：如一描述在并发量不是很高时cas机制会提高效率。
cas缺点：
1、cpu开销大，在高并发下，许多线程，更新一变量，多次更新不成功，循环反复，给cpu带来大量压力。
2、只是一个变量的原子性操作，不能保证代码块的原子性。
加版本号可以解决
##### 7. volatile原理
可见性，强制主内存的变量刷新到工作内存
禁止指令重排序，生成指令后会插入内存屏障，
读：前面LoadLoad、后面加LoadStore
写：前端StoreStore，后面加StoreLoad

##### 8. jmm内存模型
主内存 -> 工作内存模型

##### 9.CountDownLatch、CycleBarrier、Semaphore区别
计数器（主线程等其他线程完成后再执行），栅栏（所有线程统一执行到一个点，等待，然后再一起执行），信号量（控制线程数）
##### 10.什么是Happen-before以及as-if-seraial

##### 11.什么是逃逸分析

##### 12.ThrealLocal原理以及应用场景

##### 13.线程池原理，以及在正式开发中如何使用（自定义线程池，带名字，方便排查，线程池的参数如何设置），如何避免内存泄漏的问题。线程池的拒绝策略。如何自己实现拒绝策略
为什么先放队列里而不是先创建线程直到最大线程数？
fixed：corePoolSize = maximumPoolSize，LinkedBlockingQueue
singled： coolPoolSize = maximumPoolSize = 1，BlockingQueue
newCachedThreadPool： coolPoolSize = 0，maximumPoolSize=Integer.Max_value,KeepAliveTime = 60L,SynchronousQueue
newScheduledThreadPool coolPoolSize等于传入的值，maximumPoolSize=INTEGER.MAX_VALUE
##### 14. 强软弱虚四种引用的区别
软：空间足够不会回收，不够就会回收，软引用可用来实现内存敏感的高速缓存
弱：不够够不够都会回收，弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。
虚：虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之 关联的引用队列中。

##### 15.有哪些阻塞队列以及非阻塞队列
阻塞队列：ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、PriorityBlockingQueue、DelayQueue
非阻塞队列：ConcurrentLinkedQueue、LinkedTransferQueue
##### 16. 类加载的机制，双亲委派机制的好处，以及如何打破双亲委派机制。哪些中间件或者框架打破了双亲委派机制
BootStrapClassLoader、ExtClassLoader、ApplicationClassLoader
##### 17.JVM内存模型，哪些区域是线程共享的，哪些是线程私有的
堆共享，pc、本地方法栈，虚拟机栈，方法区共享（静态变量和常量在方法区）
##### 18. JVM如何判定对象是否需要被回收
引用计数法、可达性分析
##### 19.哪些对象可作为gcroot?
- 虚拟机栈中引用的对象
- 方法区中静态属性、常量引用的变量（static、final修饰的变量）
- 本地方法栈中JNDI引用的对象



##### 20.常见的垃圾回收算法，以及分代回收的流程
标志清除，内存碎片
复制 内存空间利用不足
标记整理 ，效率低
分代回收：
新生代：复制
老年代：标记-整理
新生代：老年代 = 1:2
##### 21.哪些常用的垃圾回收器，分别有什么区别
 > CMS和G1的区别
- 使用范围：CMS使用在老年代，可以配合新生代的serial和parNew收集器一起使用；G1的使用范围是来年代和新生代。不需要结合其他收集器使用。
- STW时间：CMS以最小的停顿时间为目标；G1可以预测垃圾回收的停顿时间（建立可预测的停顿时间模型）
- 垃圾碎片：CMS收集器使用标记-清除算法，容易产生内存碎片；G1使用标记-整理算法，还可以划分区域进行按区回收，降低了内存空间碎片。
- 垃圾回收过程：
CMS:1.初始标记；2.并发标记；3.重新标记；4：并发清除
G1： 1.初始标记；2：并发标记：3：最终标记：4、筛选回收

##### 22.常见的JVM参数配置
-Xms 初始堆的大小，默认为物理内存的1/64
-Xmx 最大堆大小，默认为物理内存的1/4
-Xmn 年轻代大小（1.4版本或之后的版本）。（整个堆=年轻代+老年代+持久代（1.8后移除了永久代，改为在直接内存上分配元空间））
-XX:NewSize (1.3/1.4版本)
-XX:MaxNewSize	年轻代最大值(for 1.3/1.4)
-XX:PermSize 设置持久代(perm gen)初始值
-Xss 每个线程的堆栈大小。如果栈不是很深， 应该是128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。（校长）
-XX:NewRatio 年轻代与老年代的比值
-XX:SurvivorRatio Eden区和Survivor区的比值
-XX:+UseParNewGC 设置年轻代为并行收集，可与CMS同事使用
-XX:+UseParallelOldGC 年老代垃圾收集方式为并行收集(Parallel Compacting)
-XX:+ScavengeBeforeFullGC Full GC前调用YGC
-XX:+PrintGC
-XX:+PrintGCDetails
 -XX:+HeapDumpOnOutOfMemoryError
##### 23. cpu过高如何排查
top -hp -> jstack -> 找出堆栈信息
##### 24.内存溢出如何排查，栈内存溢出如何排查，死锁如何排查，以及如何破坏死锁
-> jvm参数设置，或者手动jmap命令，然后使用mat工具
##### 25. 频繁发生FullGC如何排查
旧生代空间不足。

##### 26.垃圾回收底层原理

##### 27.有哪些常用的JVM问题排查工具

##### 28.栈桢

##### 29. TLAB问题

##### 30. 什么时候进行FullGC，什么时候进行YGC，对象什么时候进入老年代，什么是分配担保机制？
Fullgc：Permanet Generation空间满了，老年代空间不足，通过Minor GC后进入老年代的平均大小大于老年代的可用内存，systen.gc
ygc:edn空间不足

##### 31 线程池在使用过程中遇到过什么问题？
线程池未命名、不允许通过Executors创建、线程池隔离
##### 32 对象的创建过程
##### forkjoin
##### 线程池为什么要先放到队列中去而不是先创建线程以满足最大线程数































### 二、Java基础、容器

##### 1. HashMap原理

##### 2. put原理（1.7和1.8区别）

##### 3.hashMap如何进行扩容

##### 4.长度为什么要是2的幂次方

##### 5. ConcurrentHashmap原理

##### 6.ArrayList原理以及扩容机制
创建1.5倍容量的数组，调用Arrays.copyof方法复制数据
##### 7.函数式接口，lamada表达式
##### 有哪些常见的Queue，阻塞队列，非阻塞队列
##### 8 如何解决hash冲突









### 三、计算机网络以及操作系统

##### 1.什么是零拷贝zero-copy

##### 2.三次握手四次挥手，为什么是三次握手而不是两次或者四次

##### 3.linux常用命令

##### 4. TCP、UDP、Http区别。TCP重传、滑动窗口、流量控制，拥塞控制

##### epoll，select
##### HTTPS协议










### 四、Netty、NIO







### 五、Redis

##### 1.五种数据结构，底层分别是什么数据结构实现的，以及应用场景，

##### 2. 缓存雪崩、缓存穿透、缓存击穿区别以及解决方案

##### 3. 描述一下跳表

##### 4、如何保证缓存一致性，以及缓存与数据库先更新哪个
    缓存场景是非强一致性场景，根据cap理论，不可能达到强一致性，只满足AP。
    所以，我们得委曲求全，可以去做到BASE理论中说的最终一致性。
    最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性
 ######方案1：先删缓存，再更新数据库。可能存在数据不一致的问题
>  1.假设有A,B两个线程，A线程进行写操作，B线程进行读操作。
>  2.A线程先执行，将缓存删掉，写操作还未完成。B线程开始读操作，此时发现缓存中没有数据。于是读取数据库，此时B线程读到的是旧值。
>  3.B线程读到旧值后，将旧值写入缓存中。
>  4.A线程写操作完成。此时发生数据不一致的情况。
>  5.如何B线程对数据设置永不过期的话，会造成很严重的问题，缓存中永远都是错误数据。
>
###### 方案2：先更新数据库，在删缓存。在并发场景也会出现问题
可能存在的问题：A线程做查询操作，B线程做更新操作
1.缓存刚好失效。
2.请求A请求数据库，得到一个旧值。
3.线程B更新数据库，
4.然后删除缓存。
5.线程A就旧值写入缓存。此时缓存就是旧值，从而与数据库值不一致。
但要发生上述情况，需要步骤3中写数据库的操作比步骤2中的读操作更短，才会发生数据不一致的情况。但一般而言写操作比读操作是耗时要更长的，所以这种方案发生不一致问题得概率相比方案1要小很多。

**为了解决方案1、方案2导致数据不一致的问题，可以考虑达到数据最终一致性来解决**
##### 缓存延时双删
方案1延时双删步骤：
1.先淘汰缓存；2。再写缓存。3.休眠一秒，再删除一次缓存。
注意：针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。
采用上述方案吞吐量降低怎么办，可以考虑将第二次删缓存做成异步的
**如果删除缓存失败了怎么处理？**
可以使用重试机制

方案2：第二种方案：异步更新缓存(基于订阅binlog的同步机制)
    
    技术整体思路：
    
    MySQL binlog增量订阅消费+消息队列+增量数据更新到redis
    
    读Redis：热数据基本都在Redis
    写MySQL:增删改都是操作MySQL
    更新Redis数据：MySQ的数据操作binlog，来更新到Redis
    Redis更新
    
    1）数据操作主要分为两大块：
    
    一个是全量(将全部数据一次写入到redis)
    一个是增量（实时更新）
    这里说的是增量,指的是mysql的update、insert、delate变更数据。
    
    2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。
    
    这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。
    
    其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。
    
    这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果

参考文章：
https://blog.csdn.net/qq_42914528/article/details/113153537?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-1&spm=1001.2101.3001.4242



 

##### 5. redis持久化

##### 6.如何保证redis的高可用，redis的集群部署方案，以及描述一下redis cluster方案，以及如何保证集群中的节点数据一致

##### 7. redis的IO多路复用机制，以及为什么效率这么高

##### 8.如何使用redis实现分布式锁，如何生成分布式id

##### 9.在使用redis有没有遇到什么问题，在项目中使用redis做了什么

##### 10.redis过期策略以及淘汰机制

##### 11. redis为什么是原子性的，如何保证的
##### redis主从复制原理
##### bigkey会造成什么后果
##### 多主多从的架构下redis如何互相同步状态
#### 一致性hash为了解决什么问题
> 解决redis扩容时hash到原先节点上去，造成缓存雪崩的问题
##### redis bigkey会造成什么问题
##### redis哨兵机制保证高可用。
> 哨兵机制是一主多从，同时需要保证哨兵也是集群部署，避免单点故障
###### 哨兵作用
- 集群监控，负责监控master和slave的状态
- 消息通知，如果redis节点发生故障，则哨兵会发消息通知管理员
- 故障转移：如果master节点宕机，则会自动从slaver选取新的节点作为master
- 配置中心，如果发生了故障转移，则会通知client端新的master地址
###### 哨兵的高可用
- 多个哨兵节点共同监控集群状态
- 哨兵之间会互相通信，交换主从节点的状态
- 每隔1s每个哨兵会向整个集群（master+slaver+哨兵）发送一次心跳检测
一个哨兵判定主节点down叫做主观下线，超过一半的哨兵都认为主节点down，，然后哨兵相互交换判定结果，成为客观下线
##### redis复制
> 复制原理：
>   1.slaver启动时，slaver向master发送sync指令
>   2.master收到sync指令后，master节点会fork出一个子进程，子进程和父进程共享数据段，生成rdb文件快照。
>   3.当客户端有写指令时，同时master会缓存所有的写指令到缓冲区，
>   4.master发送rdb文件和写指令给slaver
>   5.slaver初始化rdb文件，并执行写指令，实现数据的同步
>   注意：在Redis2.8之后，主从断开重连后会根据断开之前最新的命令偏移量进行增量复制
##### redis主从、哨兵、集群的区别
主从：主要是为了数据备份，负载均衡，可以读写分离，一主多从模式
哨兵：为了高可用，实现故障转移
cluster：为了解决单机redis容量有限的问题，将数据按照一定的规则分发到不同的机器上，内存qps不受限与单机，可以分布式扩展

##### redis cluster
要求至少3个master，同时每个master至少需要一个slave结点


##### reids cluster集群下如何同步各个结点的状态，以及新加入的结点如何加入集群
meet消息：用于通知新节点加入。消息发送者通知接收者加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换。
ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。ping消息发送封装了自身节点和部分其他节点的状态数据。
pong消息：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内部封装了自身状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。
fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。
举例当新增一个节点，也就是Meet消息过程

节点A会为节点B创建一个clusterNode结构，并将该结构添加到自己的clusterState.nodes字典里面。
节点A根据CLUSTER MEET命令给定的IP地址和端口号，向节点B发送一条MEET消息。
节点B接收到节点A发送的MEET消息，节点B会为节点A创建一个clusterNode结构，并将该结构添加到自己的clusterState.nodes字典里面。
节点B向节点A返回一条PONG消息。
节点A将受到节点B返回的PONG消息，通过这条PONG消息节点A可以知道节点B已经成功的接收了自己发送的MEET消息。
之后，节点A将向节点B返回一条PING消息。
节点B将接收到的节点A返回的PING消息，通过这条PING消息节点B可以知道节点A已经成功的接收到了自己返回的PONG消息，握手完成。
之后，节点A会将节点B的信息通过Gossip协议传播给集群中的其他节点，让其他节点也与节点B进行握手，最终，经过一段时间后，节点B会被集群中的所有节点认识。




### 六、RPC框架
##### 1. RPC和http的区别，为什么要用rpc框架，为什么选用dubbo
##### 2.dubbo的总体架构，以及大体工作流程
##### 3.dubbo如何设置直连，一般用于本地测试
##### 4.如何升级dubbo接口
##### 5.描述一下dubbo的spi机制
##### 6.描述一下dubbo的服务暴露过程
> https://mp.weixin.qq.com/s/ISiN06QynyE2pPtX3cGQ9w
##### 7.描述一下dubbo服务引用的过程
> https://mp.weixin.qq.com/s/9oDy1OPcfDaEhKD4eNUdOA
##### 8.描述一下服务调用的过程
> https://mp.weixin.qq.com/s/oNR9v_ID2oAlEvDI93hRcw
##### 9. 为什么要封装成 invoker?
##### 10.为什么有本地协议？
##### 11.DUBBO支持的协议和序列化协议有哪几种？
##### 12.dubbo负载均衡策略
##### 13.dubbo三种调用方式
##### 14. zk有哪几种角色？











### 七、Spring以及SpringCloud
##### 1. 描述一下IOc和aop，为什么要使用ioc，aop原理
##### 2. 描述一下循环依赖以及spring是如何解决循环依赖的
> https://www.jianshu.com/p/8bb67ca11831
##### 3.描述一下bean的生命周期
> https://yemengying.com/2016/07/14/spring-bean-life-cycle/
##### 4.Spring的容器启动流程
##### 5.Spring事务的隔离级别以及传播行为
##### 6.Bean的socpe
> prototype,singleton,request、session、global session
##### 7.Springboot自动装配原理，以及如何自定义一个starter
> @springBootApplicaiton -> @EnableAutoConfighurtion -> Meta-info/SPRING.FACTORY文件下
##### 8.条件注解
##### 9.springcloud常用组件
##### 10.nacos健康检查，原理，常见的注册中心有哪几个，区别是什么，为什么选用nacos
##### 11.熔断、限流、降级、监控系统、网关、权限、日志，日志是如何进行采集上报的。有哪几种限流算法
##### gateway路由配置，以及和zuul的区别
##### 为什么使用bff层，如何分层，讲一下领域模型
##### 讲一下项目的架构图
##### ribon负载均衡有哪几种策略
> RoundRobinRule轮询（默认）、RandomRule随机、RetryRule轮询重试（重试采用的默认也是轮询）、WeightedResponseTimeRule响应速度决定权重：BestAvailableRule最优可用、AvailabilityFilteringRule
 ZoneAvoidanceRule
##### 柔性事务（最大努力送达型事务、TCC 事务）
##### 讲一下你了解的分库分表中间件的底层实现原理?
##### 熔断机制
> 
      










### 八 数据库Mysql
##### 1.innodb和myisaim区别
> 事务、行锁，外键、聚集索引，非聚集索引
##### 2.为什么使用b+树索引，索引结构，与b树的区别是
##### 3.事务的隔离级别，不同的隔离级别可能存在的问题，以及如何解决
##### 持久性的原理，redo日志
##### mvcc多版本控制，
> 只在读以提交和可重复读生效，读已提交：每一次select时都会生成一个视图；可重复读：第一次select时生成一个view，后续select都用这个view。
隐藏列trx_id，roll_pointer；
##### 出现慢sql如何排查
##### 索引优化
##### explain各个字段的含义
##### 如何保证mysql的高可用，
> 主备、读写分离
##### 分库分表实现方案
##### 数据库锁有哪几种
##### 如何设计动态扩容的分库分表方案
> 停机扩容（不推荐）倍数扩容
##### 采用分库分表后历史数据如何迁移
> 编写程序同步历史数据，再利用mq进行双写操作
##### 用过哪些分库分表中间件,有啥优点和缺点,
##### 分片策略
- 标准分片策略（StandardShardingStrategy）它只支持对单个分片健（字段）为依据的分库分表，并提供了两种分片算法 PreciseShardingAlgorithm（精准分片）和 RangeShardingAlgorithm（范围分片）。
- 复合分片策略、SQL 语句中有>，>=, <=，<，=，IN 和 BETWEEN AND 等操作符，不同的是复合分片策略支持对多个分片健操作，自定义复合分片策略要实现 ComplexKeysShardingAlgorithm 接口，重新 doSharding()方法。

- 行表达式分片策略（InlineShardingStrategy）提供对 SQL语句中的 = 和 IN 的分片操作支持，它只支持单分片健。行表达式分片策略适用于做简单的分片算法，无需自定义分片算法，省去了繁琐的代码开发，是几种分片策略中最为简单的
- Hint分片策略 
> Hint分片策略（HintShardingStrategy）相比于上面几种分片策略稍有不同，这种分片策略无需配置分片健，分片健值也不再从 SQL中解析，而是由外部指定分片信息，让 SQL在指定的分库、分表中执行。ShardingSphere 通过 Hint API实现指定操作，实际上就是把分片规则tablerule 、databaserule由集中配置变成了个性化配置。
           举个例子，如果我们希望订单表t_order用 user_id 做分片健进行分库分表，但是 t_order 表中却没有 user_id 这个字段，这时可以通过 Hint API 在外部手动指定分片健或分片库。
           













### 九、Docker以及K8S
##### docker常用命令
docker images，docker pull，docker start docker ps
docker exec -it，docker stop docker remove
##### 如何编写docker compose文件
##### K8S中pod的概念




### 十、消息队列以及Kakfa
##### rabbitmq各个名词
##### 交换机类型，fanout、direct、topic、header
##### 如何实现延时队列
##### 如何使用mq解决分布式事物，最大努力通知
##### 队列转发，通过插件可以配置队列与队列间的转发以及交换机与交换机之间的转发
##### rabbit如何保证高可用以及集群部署方案
##### kafka的架构
##### kafka为什么这么快
##### 如何保证消息不丢失，重复消费的问题，以及如何保证mq的消费顺序
> 不丢失，
生产者端丢失：开启confirm模式
MQ丢失：开启MQ持久化模式，第一种：消息持久化
               RabbitMQ 的消息默认存放在内存上面，如果不特别声明设置，消息不会持久化保存到硬盘上面的，如果节点重启或者意外crash掉，消息就会丢失。
               
               所以就要对消息进行持久化处理。如何持久化，下面具体说明下：
               
               要想做到消息持久化，必须满足以下三个条件，缺一不可。
               
               1） Exchange 设置持久化
               
               2）Queue 设置持久化
               
               3）Message持久化发送：发送消息设置发送模式deliveryMode=2，代表持久化消息
消费端丢失：关闭自动ack，需要注意保证幂等性
开启ack机制，参考https://www.cnblogs.com/cnndevelop/p/12091348.html

不重复消费：
https://www.cnblogs.com/zhixie/p/13444213.html

消息有序性：

##### kafka如何抱枕高可用
##### kafka mmaster节点挂了之后怎么办
##### kafka如何设置分区与消费者的数量关系
##### kafka主从节点数据如何同步，同步原理
##### kafak丢失数据
生产者丢失数据
0---表示不进行消息接收是否成功的确认；
1---表示当Leader接收成功时确认；
-1---表示Leader和Follower都接收成功时确认；

##### 为什么Kafka不支持读写分离？
在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。

Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:

(1)数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。

(2)延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。

##### 17.Kafka中是怎么体现消息顺序性的？
kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。
整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.
##### kafka leader选举机制
https://blog.csdn.net/yanshu2012/article/details/54894629



### 十一、项目的架构以及项目中遇到的难题
##### sharding复杂sql路由失败
##### threalLocal内存泄漏
##### 财智系统重构业务划分
##### 重构任务系统，使用设计模式优化代码，扩展性强
##### 微服务开发后本地测试较为困难，出了一套本地微服务测试方案
##### 服务平滑切换




### 十二、算法以及数据结构
##### 二分法排序
##### 链表
##### 数组操作，字符串操作
##### 二叉树的遍历，层序、锯齿、前序，中序，后序遍历
##### 拉钩教育的数据结构算法跟着写一遍




### 十三、设计模式
##### 单例模式的几种写法
##### 常用的几种设计模式以及spring中使用了哪些设计模式
##### 在项目中用了什么设计模式











