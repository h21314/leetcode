### 一、多线程及JVm


### 二、Java基础、容器

##### 1. HashMap原理

##### 2. put原理（1.7和1.8区别）

#### 为什么hashMap不是线程安全的
多个线程同时写的话数据会丢失。
1.7在并发场景下多个线程同时插入可能导致死循环。
##### 3.hashMap如何进行扩容
复制一个容量为2倍的数组，然后重新rehash
##### 4.长度为什么要是2的幂次方
可以减少碰撞几率，2的倍数 -1 得到值所有位都是1，和计算值相与后能保证结果单一，如果位上的0越多，碰撞概率越大。

比如容量是2的4次方 减1就是 1111.。。那么计算值1110过来和他相与， 结果是1110，另一个计算值1111和他相与结果仍是1111 各自结果不一样 不会碰撞 如果容量不是2的4次方 比如15 减1就是1110. 那么计算值1110过来和他相与， 结果是1110，另一个计算值1111和他相与结果是1110 跟前一个一样 发生碰撞了
##### 5. ConcurrentHashmap原理
1.7 分段锁
1.8 对Node枷锁
##### 6.ArrayList原理以及扩容机制
创建1.5倍容量的数组，调用Arrays.copyof方法复制数据
##### 7.函数式接口，lamada表达式
##### 有哪些常见的Queue，阻塞队列，非阻塞队列
##### 8 如何解决hash冲突
1、链表法，每一个桶都会对应一条链条，所有哈希值相同的元素放到相同槽位的对应的链表
2、开放寻址法：如果出现冲突，就重新探测一个空闲位置，再将元素插入。
探测方法：1、线性探测法，；2、二次探测法；3、双重散列法

##### == 和equals区别
==：基本类型：比较值是否相等；
   引用类型：比较内存地址值是否相等。每新new一个引用类型的对象，会重新分配堆内存空间，使用==比较返回false

equals：
默认情况下，比较内存地址值是否相等
可以按照需求逻辑，重写对象的equals方法。比较不同String类型对象内容是否相同，应该用equals(）
在实际使用中，一般会重写equals方法，如java.lang.String类的equals源码如下：






### 三、计算机网络以及操作系统


##### epoll，select
##### HTTPS协议










### 四、Netty、NIO


### 八 数据库Mysql



### 九、Docker以及K8S
##### docker常用命令
docker images，docker pull，docker start docker ps
docker exec -it，docker stop docker remove
##### 如何编写docker compose文件
##### K8S中pod的概念




### 十、消息队列以及Kakfa
##### zab协议
Zookeeper 是通过 Zab 协议来保证分布式事务的最终一致性。
Zab协议是为分布式协调服务Zookeeper专门设计的一种 支持崩溃恢复 的 原子广播协议 ，是Zookeeper保证数据一致性的核心算法。Zab借鉴了Paxos算法，但又不像Paxos那样，是一种通用的分布式一致性算法。它是特别为Zookeeper设计的支持崩溃恢复的原子广播协议。

在Zookeeper中主要依赖Zab协议来实现数据一致性，基于该协议，zk实现了一种主备模型（即Leader和Follower模型）的系统架构来保证集群中各个副本之间数据的一致性。
这里的主备系统架构模型，就是指只有一台客户端（Leader）负责处理外部的写事务请求，然后Leader客户端将数据同步到其他Follower节点。
Zookeeper 客户端会随机的链接到 zookeeper 集群中的一个节点，如果是读请求，就直接从当前节点中读取数据；如果是写请求，那么节点就会向 Leader 提交事务，Leader 接收到事务提交，会广播该事务，只要超过半数节点写入成功，该事务就会被提交。
https://blog.csdn.net/liuchang19950703/article/details/111406622
##### rabbitmq各个名词
##### 交换机类型，fanout（发到所有队列）、direct（路由键完全屁匹配）、topic（正则匹配）、header
##### 如何实现延时队列
业务中的使用场景：
1、任务系统中任务快要结束时如果未达成进度则会发送通知
2、订单在十分钟内未支付将会取消订单
3、账单在一周内未支付，则自动结算
4、预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议
RabbitMQ可以针对Queue和Message设置 x-message-tt，来控制消息的生存时间，如果超时，则消息变为dead letter
RabbitMQ针对队列中的消息过期时间有两种方法可以设置。

A: 通过队列属性设置，队列中所有消息都有相同的过期时间。
B: 对消息进行单独设置，每条消息TTL可以不同。
注意：如果同时设置了队列和消息的ttl，则优先取小的那个。
这两种方式是有区别的，如果设置了队列的TTL属性，那么一旦消息过期，就会被队列丢弃，而对消息设置了ttl，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间。
另外，还需要注意的一点是，如果不设置TTL，表示消息永远不会过期，如果将TTL设置为0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃


##### 什么情况下消息会变成死信？
1、消息ttl过期
2、消息被拒绝且requeue=false
3、队列达到最大长度
##### 如何使用mq解决分布式事物，最大努力通知
##### 队列转发，通过插件可以配置队列与队列间的转发以及交换机与交换机之间的转发
##### rabbit如何保证高可用以及集群部署方案
##### kafka的架构
##### kafka为什么这么快
顺序读写，sendFile使用零拷贝。批量读写、分区分段+索引
##### 如何保证消息不丢失，重复消费的问题，以及如何保证mq的消费顺序
> 不丢失，
生产者端丢失：开启confirm模式
MQ丢失：MQ接收失败或者路由失败
生产者的发送消息处理好了之后，我们就可以来看看MQ端的处理，MQ可能出现两个问题：

消息找不到对应的Exchange。

找到了Exchange但是找不到对应的Queue。

这两种情况都可以用RabbitMQ提供的mandatory参数来解决，它会设置消息投递失败的策略，有两种策略：自动删除或返回到客户端。

我们既然要做可靠性，当然是设置为返回到客户端(true是返回客户端，false是自动删除)。

开启MQ持久化模式，第一种：消息持久化
               RabbitMQ 的消息默认存放在内存上面，如果不特别声明设置，消息不会持久化保存到硬盘上面的，如果节点重启或者意外crash掉，消息就会丢失。

               所以就要对消息进行持久化处理。如何持久化，下面具体说明下：
               
               要想做到消息持久化，必须满足以下三个条件，缺一不可。
               
               1） Exchange 设置持久化
               
               2）Queue 设置持久化
               
               3）Message持久化发送：发送消息设置发送模式deliveryMode=2，代表持久化消息
1.消息持久化

2.设置集群镜像模式

3.消息补偿机制
消费端丢失：关闭自动ack，需要注意保证幂等性
开启ack机制，参考https://www.cnblogs.com/cnndevelop/p/12091348.html

不重复消费：
https://www.cnblogs.com/zhixie/p/13444213.html

消息有序性：

##### kafka如何抱枕高可用
##### kafka master节点挂了之后怎么办
##### kafka如何设置分区与消费者的数量关系
##### kafka主从节点数据如何同步，同步原理
##### kafak丢失数据
生产者丢失数据
0---表示不进行消息接收是否成功的确认；
1---表示当Leader接收成功时确认；
-1---表示Leader和Follower都接收成功时确认；

##### 为什么Kafka不支持读写分离？
在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。

Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:

(1)数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。

(2)延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。

##### 17.Kafka中是怎么体现消息顺序性的？
kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。
整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.
##### kafka leader选举机制
https://blog.csdn.net/yanshu2012/article/details/54894629



### 十一、项目的架构以及项目中遇到的难题
##### sharding复杂sql路由失败
##### threalLocal内存泄漏
##### 财智系统重构业务划分
##### 重构任务系统，使用设计模式优化代码，扩展性强
##### 微服务开发后本地测试较为困难，出了一套本地微服务测试方案
##### 服务平滑切换
hash取模方案：没有热点问题，但扩容迁移数据痛苦

range方案：不需要迁移数据，但有热点问题。
可以考虑将range方案和hash取模方案结合
先按范围分库分表，比如0-2000万分到一个group中
然后在hash将数据均匀分到不同的表或库中

今天介绍了解决“跨N库分页”这一难题的四种方法：

 

方法一：全局视野法

（1）将order by time offset X limit Y，改写成order by time offset 0 limit X+Y

（2）服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录

这种方法随着翻页的进行，性能越来越低。

 

方法二：业务折衷法-禁止跳页查询

（1）用正常的方法取得第一页数据，并得到第一页记录的time_max

（2）每次翻页，将order by time offset X limit Y，改写成order by time where time>$time_max limit Y

以保证每次只返回一页数据，性能为常量。

 

方法三：业务折衷法-允许模糊数据

（1）将order by time offset X limit Y，改写成order by time offset X/N limit Y/N

 

方法四：二次查询法

（1）将order by time offset X limit Y，改写成order by time offset X/N limit Y

（2）找到最小值time_min

（3）between二次查询，order by time between $time_min and $time_i_max

（4）设置虚拟time_min，找到time_min在各个分库的offset，从而得到time_min在全局的offset

（5）得到了time_min在全局的offset，自然得到了全局的offset X limit Y




### 十二、算法以及数据结构
##### 二分法排序
##### 链表
##### 数组操作，字符串操作
##### 二叉树的遍历，层序、锯齿、前序，中序，后序遍历
##### 拉钩教育的数据结构算法跟着写一遍




### 十三、设计模式
##### 单例模式的几种写法
##### 常用的几种设计模式以及spring中使用了哪些设计模式
##### 在项目中用了什么设计模式

##### 如何判断一个数是否在40亿个整数中
bitmap

##### 如何在10亿个数中找出前1000大的数
采用分治的思想，分成若干的文件，在每个文件中找出前1000，然后再结果中再进行排序。
可以维护一个最大堆

### 如何对一个大文件中的数据排序












