### 五、Redis

##### 1.五种数据结构，底层分别是什么数据结构实现的，以及应用场景，
https://www.cnblogs.com/hunternet/p/11306690.html
zset 压缩列表（ 压缩列表(zip1ist)是列表和哈希的底层实现之一。），跳表
##### 2. 缓存雪崩、缓存穿透、缓存击穿区别以及解决方案
缓存雪崩：
- 过期时间加随机值
- 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中
- 设置热点数据永远不过期。
缓存穿透：
- 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
- 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
- 布隆过滤器

缓存击穿：
- 设置热点数据永远不过期。
- 加互斥锁，互斥锁参考代码如下：
##### 3. 描述一下跳表

##### 4、如何保证缓存一致性，以及缓存与数据库先更新哪个
    缓存场景是非强一致性场景，根据cap理论，不可能达到强一致性，只满足AP。
    所以，我们得委曲求全，可以去做到BASE理论中说的最终一致性。
    最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性
 ######方案1：先删缓存，再更新数据库。可能存在数据不一致的问题
>  1.假设有A,B两个线程，A线程进行写操作，B线程进行读操作。
>  2.A线程先执行，将缓存删掉，写操作还未完成。B线程开始读操作，此时发现缓存中没有数据。于是读取数据库，此时B线程读到的是旧值。
>  3.B线程读到旧值后，将旧值写入缓存中。
>  4.A线程写操作完成。此时发生数据不一致的情况。
>  5.如何B线程对数据设置永不过期的话，会造成很严重的问题，缓存中永远都是错误数据。
###### 方案2：先更新数据库，在删缓存。在并发场景也会出现问题
可能存在的问题：A线程做查询操作，B线程做更新操作
1.缓存刚好失效。
2.请求A请求数据库，得到一个旧值。
3.线程B更新数据库，
4.然后删除缓存。
5.线程A就旧值写入缓存。此时缓存就是旧值，从而与数据库值不一致。
但要发生上述情况，需要步骤3中写数据库的操作比步骤2中的读操作更短，才会发生数据不一致的情况。但一般而言写操作比读操作是耗时要更长的，所以这种方案发生不一致问题得概率相比方案1要小很多。

**为了解决方案1、方案2导致数据不一致的问题，可以考虑达到数据最终一致性来解决**
##### 缓存延时双删
方案1延时双删步骤：
1.先淘汰缓存；2。再写数据库（这两步和原来一样）。3.休眠一秒，再删除一次缓存。
注意：针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。
采用上述方案吞吐量降低怎么办，可以考虑将第二次删缓存做成异步的
**如果删除缓存失败了怎么处理？**
可以使用重试机制

方案2：第二种方案：异步更新缓存(基于订阅binlog的同步机制)
    
    技术整体思路：
    
    MySQL binlog增量订阅消费+消息队列+增量数据更新到redis
    
    读Redis：热数据基本都在Redis
    写MySQL:增删改都是操作MySQL
    更新Redis数据：MySQ的数据操作binlog，来更新到Redis
    Redis更新
    
    1）数据操作主要分为两大块：
    
    一个是全量(将全部数据一次写入到redis)
    一个是增量（实时更新）
    这里说的是增量,指的是mysql的update、insert、delate变更数据。
    
    2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。
    
    这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。
    
    其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。
    
    这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果

参考文章：
https://blog.csdn.net/qq_42914528/article/details/113153537?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-1&spm=1001.2101.3001.4242



 

##### 5. redis持久化
1、RDB
2、AOF
##### 6.如何保证redis的高可用，redis的集群部署方案，以及描述一下redis cluster方案，以及如何保证集群中的节点数据一致
1、redis一主多从，加哨兵机制。可以实现故障转移。
2、使用redis cluster集群方案
##### 7. redis的IO多路复用机制，以及为什么效率这么高
IO多路复用程序会同时监听多个socket，当被监听的socket准备好执行accept、read、write、close等操作时，
与这些操作相对应的文件事件就会产生。IO多路复用程序会把所有产生事件的socket压入一个队列中，
然后有序地每次仅一个socket的方式传送给文件事件分派器，
文件事件分派器接收到socket之后会根据socket产生的事件类型调用对应的事件处理器进行处理。
##### 8.如何使用redis实现分布式锁，如何生成分布式id
利用 redis 单线程,不能存储相同key,可以设置存储数据失效的特性实现分布式锁,重点方法时setnx(),存储,存储成功返回1,失败返回0,
需要设置超时时间，防止服务宕机后无法释放锁。
要想实现可重入锁，需要通过lua脚本实现
脚本如下：
```
if redis.call("get", KEYS[1]) == ARGV[1] then 
     return redis.call("del", KEYS[1]) 
 else 
     return 0 
 end 
```
##### 9.在使用redis有没有遇到什么问题，在项目中使用redis做了什么
实现幂等
##### 15、分布式锁，redisson是如何解决死锁问题
https://blog.csdn.net/luokn1995/article/details/108371863

分布式锁的各种坑，以及解决方案。参考下列
> http://www.360doc.com/content/20/0428/07/58006001_908837125.shtml
1）获取当前时间。

2）依次获取N个节点的锁。每个节点加锁的实现方式同上。这里有个细节，就是每次获取锁的时候的过期时间都不同，需要减去之前获取锁的操作的耗时：

比如传入的锁的过期时间为500ms；

获取第一个节点的锁花了1ms，那么第一个节点的锁的过期时间就是499ms；

获取第二个节点的锁花了2ms，那么第二个节点的锁的过期时间就是497ms；

如果锁的过期时间小于等于0了，说明整个获取锁的操作超时了，整个操作失败。

3）判断是否获取锁成功。如果client在上述步骤中获取到了(N/2 + 1)个节点锁，并且每个锁的过期时间都是大于0的，则获取锁成功，否则失败。失败时释放锁。

4）释放锁。对所有节点发送释放锁的指令，每个节点的实现逻辑和上面的简单实现一样。为什么要对所有节点操作？因为分布式场景下从一个节点获取锁失败不代表在那个节点上加速失败，可能实际上加锁已经成功了，但是返回时因为网络抖动超时了

##### 10.redis过期策略以及淘汰机制
redis的过期策略是：定期删除+惰性删除.
redis 内存淘汰机制（内存淘汰策略）有以下几个：
• noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。
• allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。
• allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。
• volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。
• volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。
• volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。

allkeys-lru：如果我们的应用对缓存的访问符合幂律分布，也就是存在相对热点数据，或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择allkeys-lru策略。

allkeys-random：如果我们的应用对于缓存key的访问概率相等，则可以使用这个策略。

volatile-ttl：这种策略使得我们可以向Redis提示哪些key更适合被eviction。
##### 11. redis为什么是原子性的，如何保证的
因为Redis是单线程的。Redis本身提供的所有API都是原子操作，Redis中的事务其实是要保证批量操作的原子性。

##### bigkey会造成什么后果?
如果下面两种情况，我就会认为它是bigkey。

字符串类型：它的big体现在单个value值很大，一般认为超过10KB就是bigkey。
非字符串类型：哈希、列表、集合、有序集合，它们的big体现在元素个数太多。
危害：
1.内存空间不均匀。这样会不利于集群对内存的统一管理，存在丢失数据的隐患。
2.超时阻塞。由于Redis单线程的特性，操作bigkey的通常比较耗时，也就意味着阻塞Redis可能性越大，这样会造成客户端阻塞或者引起故障切换，它们通常出现在慢查询中。
3.网络拥塞。bigkey也就意味着每次获取要产生的网络流量较大
4..过期删除。就会存在阻塞Redis的可能性，而且这个过期删除不会从主节点的慢查询发现
5.迁移困难。当需要对bigkey进行迁移（例如Redis cluster的迁移slot），实际上是通过migrate命令来完成的，migrate实际上是通过dump + restore + del三个命令组合成原子命令完成，如果是bigkey，可能会使迁移失败，而且较慢的migrate会阻塞Redis。

bigkey怎么产生的？
 一般来说，bigkey的产生都是由于程序设计不当，或者对于数据规模预料不清楚造成的，来看几个：

 (1) 社交类：粉丝列表，如果某些明星或者大v不精心设计下，必是bigkey。

 (2) 统计类：例如按天存储某项功能或者网站的用户集合，除非没几个人用，否则必是bigkey。

 (3) 缓存类：将数据从数据库load出来序列化放到Redis里，这个方式非常常用，但有两个地方需要注意:

 第一，是不是有必要把所有字段都缓存
 第二，有没有相关关联的数据
 例如遇到过一个例子，该同学将某明星一个专辑下所有视频信息都缓存一个巨大的json中，造成这个json达到6MB，后来这个明星发了一个官宣
 bigkey怎么发现？
 redis-cli提供了--bigkeys来查找bigkey

 如何优化bigkey？
 1、拆分
 2、
##### 多主多从的架构下redis如何互相同步状态
#### 一致性hash为了解决什么问题
> 解决redis扩容时hash到原先节点上去，造成缓存雪崩的问题
>https://blog.csdn.net/cy973071263/article/details/104497894

一致性hash原理
一致性Hash算法也是使用取模的方法，不过，上述的取模方法是对服务器的数量进行取模，而一致性的Hash算法是对2的32方取模。即，一致性Hash算法将整个Hash空间组织成一个虚拟的圆环，Hash函数的值空间为0 ~ 2^32 - 1(一个32位无符号整型)
将数据Key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针查找，遇到的服务器就是其应该定位到的服务器。
一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，有很好的容错性和可扩展性。

一致性hash算法如何解决数据倾斜问题？
为了解决数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务器节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。
一致性哈希的哈希槽数为什么是2^32

一致性哈希一定程度上也解决了哈希冲突，只要哈希槽的范围足够大就能尽可能的减少哈希冲突，因为通常的hashCode都是将数据映射到0 ~ 2^32 数值空间内，所以设置一个2^32个节点的哈希环会尽可能的减少哈希冲突。

##### redis哨兵机制保证高可用。
> 哨兵机制是一主多从，同时需要保证哨兵也是集群部署，避免单点故障
###### 哨兵作用
- 集群监控，负责监控master和slave的状态
- 消息通知，如果redis节点发生故障，则哨兵会发消息通知管理员
- 故障转移：如果master节点宕机，则会自动从slaver选取新的节点作为master
- 配置中心，如果发生了故障转移，则会通知client端新的master地址
###### 哨兵的高可用
- 多个哨兵节点共同监控集群状态
- 哨兵之间会互相通信，交换主从节点的状态
- 每隔1s每个哨兵会向整个集群（master+slaver+哨兵）发送一次心跳检测
一个哨兵判定主节点down叫做主观下线，超过一半的哨兵都认为主节点down，，然后哨兵相互交换判定结果，成为客观下线
##### redis复制
全量同步：
> 复制原理：
>   1.slaver启动时，slaver向master发送sync指令
>   2.master收到sync指令后，master节点会fork出一个子进程，子进程和父进程共享数据段，生成rdb文件快照。
>   3.当客户端有写指令时，同时master会缓存所有的写指令到缓冲区，
>   4.master发送rdb文件和写指令给slaver
>   5.slaver初始化rdb文件，并执行写指令，实现数据的同步
>   注意：在Redis2.8之后，主从断开重连后会根据断开之前最新的命令偏移量进行增量复制

增量：
Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 
增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令
##### redis主从、哨兵、集群的区别
主从：主要是为了数据备份，负载均衡，可以读写分离，一主多从模式
哨兵：为了高可用，实现故障转移
cluster：为了解决单机redis容量有限的问题，将数据按照一定的规则分发到不同的机器上，内存qps不受限与单机，可以分布式扩展

##### redis cluster
要求至少3个master，同时每个master至少需要一个slave结点
1.把16384槽按照节点数量进行平均分配，由节点进行管理
2.对每个key按照CRC16规则进行hash运算
3.把hash结果对16383进行取余
4.把余数发送给Redis节点
5.节点接收到数据，验证是否在自己管理的槽编号的范围
    如果在自己管理的槽编号范围内，则把数据保存到数据槽中，然后返回执行结果
    如果在自己管理的槽编号范围外，则会把数据发送给正确的节点，由正确的节点来把数据保存在对应的槽中
https://www.cnblogs.com/williamjie/p/11132211.html

Redis Cluster中的读、写请求其实都是在master上完成的。

##### reids cluster集群下如何同步各个结点的状态，以及新加入的结点如何加入集群
meet消息：用于通知新节点加入。消息发送者通知接收者加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换。
ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。ping消息发送封装了自身节点和部分其他节点的状态数据。
pong消息：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内部封装了自身状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。
fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。
举例当新增一个节点，也就是Meet消息过程

节点A会为节点B创建一个clusterNode结构，并将该结构添加到自己的clusterState.nodes字典里面。
节点A根据CLUSTER MEET命令给定的IP地址和端口号，向节点B发送一条MEET消息。
节点B接收到节点A发送的MEET消息，节点B会为节点A创建一个clusterNode结构，并将该结构添加到自己的clusterState.nodes字典里面。
节点B向节点A返回一条PONG消息。
节点A将受到节点B返回的PONG消息，通过这条PONG消息节点A可以知道节点B已经成功的接收了自己发送的MEET消息。
之后，节点A将向节点B返回一条PING消息。
节点B将接收到的节点A返回的PING消息，通过这条PING消息节点B可以知道节点A已经成功的接收到了自己返回的PONG消息，握手完成。
之后，节点A会将节点B的信息通过Gossip协议传播给集群中的其他节点，让其他节点也与节点B进行握手，最终，经过一段时间后，节点B会被集群中的所有节点认识。
##### 布隆过滤器原理
.应用场景，网页黑名单，垃圾邮件过滤，电话黑名单，url去重，内容推荐等
存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素
删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断
##### 什么是分布式共识算法
> 在一个分布式系统中，如何保证集群中所有节点中的数据完全相同并且能够对某个提案（Proposal）达成一致是分布式系统正常工作的核心问题，而共识算法就是用来保证分布式系统一致性的方法。

Paxos算法：
Raft算法：
Zab



##### redis什么时候全量，什么时候增量，从节点挂掉之后重新连上后是全量同步，判断依据

为了方便下面讲解，我们这里把节点A叫做master节点，节点B叫做slave节点。

当我们在slave上执行slaveof命令时，这个复制流程会经过以下阶段：

slave发送psync $runid $offset给master，请求同步数据
master检查slave发来的runid和offset参数，决定是发送全量数据还是部分数据
如果slave是第一次与master同步，或者master-slave断开复制太久，则进行全量同步
master在后台生成RDB快照文件，通过网络发给slave
slave接收到RDB文件后，清空自己本地数据库
slave加载RDB数据到内存中
如果master-slave之前已经建立过数据同步，只是因为某些原因断开了复制，此时只同步部分数据
master根据slave发来的数据位置offset，只发送这个位置之后的数据给slave
slave接收这些差异数据，更新自己的数据，与maser保持一致
之后master产生的写入，都会传播一份给slave，slave与master保持实时同步
下面分别介绍全量同步和部分同步的详细流程。
当我们在节点B上执行slaveof命令后，节点B会与节点A建立一个TCP连接，然后发送psync $runid $offset命令，告知节点A需要开始同步数据。

这两个参数的具体含义如下：

runid：master节点的唯一标识
offset：slave需要从哪个位置开始同步数据
什么是runid？在启动Redis实例时，Redis会为每个实例随机分配一个长度为40位的十六进制字符串，用来标识实例的唯一性，也就是说，runid就是这个实例的唯一标识。

由于是第一次同步，slave并不知道master的runid，所以slave会r发送psync ? -1，表示需要全量同步数据。

master在收到slave发来的psync后，会给slave回复+fullsync $runid $offset，这个runid就是master的唯一标识，slave会记录这个runid，用于后续断线重连同步请求。
原文链接：https://blog.csdn.net/weixin_45784983/article/details/107208856

##### redis的hash数据结构是怎么rehash的，如何保证高并发场景下的rehash

##### 一致性hash存在的问题
有可能数据不均衡。

虚拟节点机制
但是一致性哈希也存在自身的小问题，例如当我们的Redis节点分布如下时，就有问题了。



此时数据落在节点A上的概率明显是大于其他两个节点的，其次落在节点C上的概率最小。这样一来会导致整个集群的数据存储不平衡，AB节点压力较大，而C节点资源利用不充分。为了解决这个问题，一致性哈希算法引入了虚拟节点机制。



在圆环中，增加了对应节点的虚拟节点，然后完成了虚拟节点到真实节点的映射。假设现在计算得出了位置D，那么按照顺时针的顺序，我们找到的第一个节点就是C #1，最终数据实际还是会落在节点C上。

通过增加虚拟节点的方式，使ABC三个节点在圆环上的位置更加均匀，平均了落在每一个节点上的概率。这样一来就解决了上文提到的数据存储存在不均匀的问题了，这就是一致性哈希的虚拟节点机制。
原文链接：https://blog.csdn.net/weixin_42667608/article/details/111360617

### redis主从结构下如何进行master的选举
